,mutation,Mean(LP),Std(Speed),Std(SA),Max(LP),Max(Acc),Max(SA),Mean(SA),Mean(SAS),Std(SAS),Mean(LS),Std(LS),Min(LP),Std(LP),Max(Speed),Mean(Acc),Min(Acc),Std(Acc),Mean(TPP),Std(TPP)
0,udacity_add_weights_regularisation_mutated0_MP_l1_3,"('killed: True', 'Sector number: 15', ' p_value: 0.033', ' effect_size: -0.6736344385129982')","('killed: True', 'Sector number: 5', ' p_value: 0.035', ' effect_size: 0.6683997591668888')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.026', ' effect_size: -0.703690342432435')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: 0.9192807966820351')",Not killed by this metric,"('killed: True', 'Sector number: 7', ' p_value: 0.024', ' effect_size: -0.7156580579144621')","('killed: True', 'Sector number: 3', ' p_value: 0.013', ' effect_size: 0.7840454509980505')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.048', ' effect_size: -0.6248857798660652')","('killed: True', 'Sector number: 14', ' p_value: 0.002', ' effect_size: -0.9627426006685005')","('killed: True', 'Sector number: 13', ' p_value: 0.019', ' effect_size: -0.7430350590691734')","('killed: True', 'Sector number: 10', ' p_value: 0.015', ' effect_size: -0.7678403086565818')",Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.025', ' effect_size: 0.708263567220224')",Not killed by this metric
1,udacity_change_activation_function_mutated0_MP_exponential_4,"('killed: True', 'Sector number: 10', ' p_value: 0.011', ' effect_size: -0.8086449978171637')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.004', ' effect_size: -0.9069362874192146')","('killed: True', 'Sector number: 10', ' p_value: 0.007', ' effect_size: -0.8548583882064615')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.2756997601365636')","('killed: True', 'Sector number: 2', ' p_value: 0.031', ' effect_size: -0.6825887374043978')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 26', ' p_value: 0.021', ' effect_size: -0.7292592012962624')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.007', ' effect_size: -0.8516669844843666')","('killed: True', 'Sector number: 13', ' p_value: 0.038', ' effect_size: -0.65768693320643')","('killed: True', 'Sector number: 10', ' p_value: 0.003', ' effect_size: -0.9285815150747921')","('killed: True', 'Sector number: 2', ' p_value: 0.029', ' effect_size: 0.6890157403416026')","('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: 0.9310096517851365')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.019', ' effect_size: -0.744488287922426')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.015', ' effect_size: -0.7727291516429037')"
2,udacity_change_activation_function_mutated0_MP_hard_sigmoid_4,"('killed: True', 'Sector number: 12', ' p_value: 0.045', ' effect_size: -0.6331756827151479')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.027', ' effect_size: -0.7009615167458941')","('killed: True', 'Sector number: 11', ' p_value: 0.002', ' effect_size: -0.9961000235074138')","('killed: True', 'Sector number: 0', ' p_value: 0.015', ' effect_size: 0.7712450586653421')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: -0.8383827275218675')","('killed: True', 'Sector number: 14', ' p_value: 0.034', ' effect_size: -0.6710282484962498')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 20', ' p_value: 0.032', ' effect_size: -0.6790006204918824')","('killed: True', 'Sector number: 12', ' p_value: 0.018', ' effect_size: -0.7452617123763643')",Not killed by this metric,"('killed: True', 'Sector number: 11', ' p_value: 0.006', ' effect_size: -0.8714738444238855')","('killed: True', 'Sector number: 17', ' p_value: 0.042', ' effect_size: 0.6438781315646107')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.028', ' effect_size: 0.6964010353922248')","('killed: True', 'Sector number: 3', ' p_value: 0.014', ' effect_size: -0.7754619658556495')","('killed: True', 'Sector number: 13', ' p_value: 0.027', ' effect_size: 0.7002295354876578')","('killed: True', 'Sector number: 13', ' p_value: 0.032', ' effect_size: -0.6774379892530856')"
3,udacity_change_activation_function_mutated0_MP_relu_4,"('killed: True', 'Sector number: 12', ' p_value: 0.032', ' effect_size: -0.676761652939133')","('killed: True', 'Sector number: 2', ' p_value: 0.042', ' effect_size: 0.6425586801479437')","('killed: True', 'Sector number: 2', ' p_value: 0.01', ' effect_size: -0.8148811458950751')","('killed: True', 'Sector number: 10', ' p_value: 0.029', ' effect_size: -0.6916094093371413')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.3416061570137756')",Not killed by this metric,"('killed: True', 'Sector number: 7', ' p_value: 0.012', ' effect_size: -0.7949820730738206')",Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.131250038612028')","('killed: True', 'Sector number: 3', ' p_value: 0.015', ' effect_size: -0.7699070135040662')","('killed: True', 'Sector number: 10', ' p_value: 0.005', ' effect_size: -0.8839246601009844')","('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: 0.8276855371569868')","('killed: True', 'Sector number: 2', ' p_value: 0.004', ' effect_size: 0.9092981587084961')","('killed: True', 'Sector number: 20', ' p_value: 0.012', ' effect_size: 0.7977404972676898')","('killed: True', 'Sector number: 3', ' p_value: 0.048', ' effect_size: -0.6255071816465047')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.033', ' effect_size: -0.6738465222422562')"
4,udacity_change_activation_function_mutated0_MP_softsign_4,"('killed: True', 'Sector number: 19', ' p_value: 0.01', ' effect_size: -0.8170995914125408')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.023', ' effect_size: -0.7201809271347349')","('killed: True', 'Sector number: 10', ' p_value: 0.026', ' effect_size: -0.705325034478532')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: 1.065342401851481')",Not killed by this metric,"('killed: True', 'Sector number: 6', ' p_value: 0.048', ' effect_size: -0.6261073505177637')","('killed: True', 'Sector number: 3', ' p_value: 0.019', ' effect_size: 0.7396082675814533')","('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: -0.8507981967054207')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.038', ' effect_size: -0.6544630188305777')","('killed: True', 'Sector number: 13', ' p_value: 0.022', ' effect_size: -0.7247160250484435')","('killed: True', 'Sector number: 10', ' p_value: 0.015', ' effect_size: -0.767967786724759')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.019', ' effect_size: 0.7438528369142079')","('killed: True', 'Sector number: 4', ' p_value: 0.039', ' effect_size: 0.6541904486361475')","('killed: True', 'Sector number: 3', ' p_value: 0.021', ' effect_size: -0.7286057123018156')","('killed: True', 'Sector number: 15', ' p_value: 0.011', ' effect_size: 0.8011625526172614')","('killed: True', 'Sector number: 15', ' p_value: 0.028', ' effect_size: -0.6932603796548229')"
5,udacity_change_dropout_rate_mutated0_MP_0.75_0.75_6,"('killed: True', 'Sector number: 17', ' p_value: 0.022', ' effect_size: -0.7225003151143707')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0578506285389646')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: -1.1270065342817022')","('killed: True', 'Sector number: 10', ' p_value: 0.028', ' effect_size: -0.695494964055182')","('killed: True', 'Sector number: 0', ' p_value: 0.003', ' effect_size: 0.9245458341777472')","('killed: True', 'Sector number: 13', ' p_value: 0.036', ' effect_size: -0.6622492151826685')","('killed: True', 'Sector number: 1', ' p_value: 0.022', ' effect_size: -0.722110164480621')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: 0.9973612964470138')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.012', ' effect_size: -0.7965105840689866')","('killed: True', 'Sector number: 6', ' p_value: 0.043', ' effect_size: -0.6396895017583433')","('killed: True', 'Sector number: 10', ' p_value: 0.032', ' effect_size: -0.6785394221163863')","('killed: True', 'Sector number: 11', ' p_value: 0.032', ' effect_size: -0.6772185574852988')","('killed: True', 'Sector number: 2', ' p_value: 0.013', ' effect_size: 0.7865528048225392')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0372414895054964')","('killed: True', 'Sector number: 15', ' p_value: 0.023', ' effect_size: 0.7170138946655765')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1695201457440445')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0350091803915993')","('killed: True', 'Sector number: 2', ' p_value: 0.027', ' effect_size: -0.7010838453161471')"
6,udacity_change_epochs_mutated0_MP_50_14,"('killed: True', 'Sector number: 3', ' p_value: 0.045', ' effect_size: -0.6350095942370346')","('killed: True', 'Sector number: 6', ' p_value: 0.012', ' effect_size: 0.7974035584039189')","('killed: True', 'Sector number: 16', ' p_value: 0.002', ' effect_size: -0.9645824272412806')","('killed: True', 'Sector number: 0', ' p_value: 0.043', ' effect_size: -0.6394931315815395')","('killed: True', 'Sector number: 0', ' p_value: 0.024', ' effect_size: 0.7154012056688798')","('killed: True', 'Sector number: 16', ' p_value: 0.001', ' effect_size: -1.0725162968209807')","('killed: True', 'Sector number: 6', ' p_value: 0.008', ' effect_size: -0.8454323722596812')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: 1.0699931631343476')","('killed: True', 'Sector number: 16', ' p_value: 0.006', ' effect_size: -0.8651668387383559')","('killed: True', 'Sector number: 0', ' p_value: 0.009', ' effect_size: -0.8213719868743269')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.018', ' effect_size: -0.7481689669871697')","('killed: True', 'Sector number: 4', ' p_value: 0.005', ' effect_size: -0.8889905966517405')","('killed: True', 'Sector number: 6', ' p_value: 0.0', ' effect_size: 1.1649647450628229')","('killed: True', 'Sector number: 9', ' p_value: 0.042', ' effect_size: 0.6439889218678333')","('killed: True', 'Sector number: 16', ' p_value: 0.0', ' effect_size: 1.269088427608972')","('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: -0.8272957937109291')","('killed: True', 'Sector number: 5', ' p_value: 0.04', ' effect_size: 0.6483022015624718')","('killed: True', 'Sector number: 0', ' p_value: 0.038', ' effect_size: -0.6561267228538152')"
7,udacity_change_epochs_mutated0_MP_50_20,"('killed: True', 'Sector number: 7', ' p_value: 0.041', ' effect_size: -0.6476176810858284')","('killed: True', 'Sector number: 6', ' p_value: 0.019', ' effect_size: 0.7425312939749771')","('killed: True', 'Sector number: 16', ' p_value: 0.006', ' effect_size: -0.8699775845919738')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.0740941358662532')","('killed: True', 'Sector number: 0', ' p_value: 0.013', ' effect_size: 0.7827638693989678')","('killed: True', 'Sector number: 16', ' p_value: 0.024', ' effect_size: -0.7127011780112917')","('killed: True', 'Sector number: 6', ' p_value: 0.035', ' effect_size: -0.6662228569737118')","('killed: True', 'Sector number: 9', ' p_value: 0.001', ' effect_size: 1.0735269298730685')",Not killed by this metric,"('killed: True', 'Sector number: 4', ' p_value: 0.029', ' effect_size: -0.6893518806591056')","('killed: True', 'Sector number: 20', ' p_value: 0.001', ' effect_size: -1.03257323000411')","('killed: True', 'Sector number: 3', ' p_value: 0.035', ' effect_size: -0.6681046739945482')","('killed: True', 'Sector number: 11', ' p_value: 0.036', ' effect_size: -0.6634118164558791')","('killed: True', 'Sector number: 6', ' p_value: 0.0', ' effect_size: 1.3232817497198062')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0177164921282205')","('killed: True', 'Sector number: 24', ' p_value: 0.002', ' effect_size: 0.9945050180847801')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -1.0032394067495194')","('killed: True', 'Sector number: 5', ' p_value: 0.044', ' effect_size: 0.6359611726001937')","('killed: True', 'Sector number: 15', ' p_value: 0.039', ' effect_size: -0.6538563008636014')"
8,udacity_change_epochs_mutated0_MP_50_23,"('killed: True', 'Sector number: 15', ' p_value: 0.007', ' effect_size: -0.8549738517748741')","('killed: True', 'Sector number: 4', ' p_value: 0.006', ' effect_size: 0.8730450388980896')","('killed: True', 'Sector number: 16', ' p_value: 0.014', ' effect_size: -0.775227673570133')","('killed: True', 'Sector number: 15', ' p_value: 0.03', ' effect_size: -0.6846536376193756')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: 1.0356912979196844')","('killed: True', 'Sector number: 16', ' p_value: 0.034', ' effect_size: -0.669710385777582')","('killed: True', 'Sector number: 4', ' p_value: 0.013', ' effect_size: -0.7812017936653778')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: 0.9110076217005714')",Not killed by this metric,"('killed: True', 'Sector number: 7', ' p_value: 0.001', ' effect_size: -1.0985452047862543')","('killed: True', 'Sector number: 14', ' p_value: 0.019', ' effect_size: -0.7437383487665679')","('killed: True', 'Sector number: 15', ' p_value: 0.019', ' effect_size: -0.7429244395140333')","('killed: True', 'Sector number: 14', ' p_value: 0.043', ' effect_size: -0.639249797587078')","('killed: True', 'Sector number: 6', ' p_value: 0.0', ' effect_size: 1.1064181279294942')","('killed: True', 'Sector number: 9', ' p_value: 0.039', ' effect_size: 0.652360638294326')","('killed: True', 'Sector number: 24', ' p_value: 0.008', ' effect_size: 0.8351987129795652')","('killed: True', 'Sector number: 3', ' p_value: 0.036', ' effect_size: -0.6638427803475159')","('killed: True', 'Sector number: 5', ' p_value: 0.006', ' effect_size: 0.861231379241078')","('killed: True', 'Sector number: 24', ' p_value: 0.007', ' effect_size: -0.8525375441937021')"
9,udacity_change_epochs_mutated0_MP_50_26,"('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: -0.9506067147318641')","('killed: True', 'Sector number: 6', ' p_value: 0.009', ' effect_size: 0.8261660199212962')","('killed: True', 'Sector number: 24', ' p_value: 0.042', ' effect_size: -0.642680732876945')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.0125909857898117')","('killed: True', 'Sector number: 0', ' p_value: 0.003', ' effect_size: 0.9405684424420686')",Not killed by this metric,"('killed: True', 'Sector number: 8', ' p_value: 0.027', ' effect_size: -0.7002451272779713')","('killed: True', 'Sector number: 7', ' p_value: 0.029', ' effect_size: 0.6922261147517837')",Not killed by this metric,"('killed: True', 'Sector number: 7', ' p_value: 0.003', ' effect_size: -0.9457684568549273')","('killed: True', 'Sector number: 3', ' p_value: 0.031', ' effect_size: -0.6823716492941879')","('killed: True', 'Sector number: 19', ' p_value: 0.033', ' effect_size: -0.6752341188841036')","('killed: True', 'Sector number: 14', ' p_value: 0.001', ' effect_size: -1.0396281738099076')",Not killed by this metric,"('killed: True', 'Sector number: 13', ' p_value: 0.044', ' effect_size: 0.6380389595478498')","('killed: True', 'Sector number: 24', ' p_value: 0.024', ' effect_size: 0.7158082274934255')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.5556933982784527')","('killed: True', 'Sector number: 1', ' p_value: 0.048', ' effect_size: 0.6252285241892845')",Not killed by this metric
10,udacity_change_epochs_mutated0_MP_50_38,"('killed: True', 'Sector number: 15', ' p_value: 0.04', ' effect_size: -0.6502012448191814')","('killed: True', 'Sector number: 6', ' p_value: 0.044', ' effect_size: 0.6375178620165217')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: -0.9430448680880517')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: 0.8347066758569136')",Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 20', ' p_value: 0.003', ' effect_size: -0.930976457930326')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.032', ' effect_size: -0.6774006579891959')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.031', ' effect_size: 0.6839662366902943')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3611018924284053')",Not killed by this metric,Not killed by this metric
11,udacity_change_epochs_mutated0_MP_50_44,"('killed: True', 'Sector number: 0', ' p_value: 0.02', ' effect_size: -0.7344225810670693')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.024', ' effect_size: -0.7136544894186325')","('killed: True', 'Sector number: 0', ' p_value: 0.036', ' effect_size: -0.6615782621866549')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.7217183852274394')","('killed: True', 'Sector number: 26', ' p_value: 0.031', ' effect_size: -0.6812926579194368')","('killed: True', 'Sector number: 21', ' p_value: 0.041', ' effect_size: -0.6477429518443664')","('killed: True', 'Sector number: 26', ' p_value: 0.018', ' effect_size: 0.7477436499547767')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.01', ' effect_size: -0.817078676161311')","('killed: True', 'Sector number: 14', ' p_value: 0.007', ' effect_size: -0.8502439989382609')","('killed: True', 'Sector number: 13', ' p_value: 0.028', ' effect_size: -0.6964179999732033')","('killed: True', 'Sector number: 10', ' p_value: 0.003', ' effect_size: -0.9398254976991238')","('killed: True', 'Sector number: 6', ' p_value: 0.029', ' effect_size: 0.6925925340321551')","('killed: True', 'Sector number: 2', ' p_value: 0.018', ' effect_size: 0.7505295457482435')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.003', ' effect_size: -0.9340415051373403')","('killed: True', 'Sector number: 15', ' p_value: 0.008', ' effect_size: 0.8344718502673113')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: -0.8435151067139558')"
12,udacity_change_label_mutated0_MP_100,"('killed: True', 'Sector number: 9', ' p_value: 0.035', ' effect_size: -0.6674065178841061')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.805398760458256')","('killed: True', 'Sector number: 0', ' p_value: 0.019', ' effect_size: -0.7434329338525963')","('killed: True', 'Sector number: 0', ' p_value: 0.02', ' effect_size: 0.7345650941569551')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.181965301942251')","('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: -1.024748156791863')","('killed: True', 'Sector number: 0', ' p_value: 0.042', ' effect_size: 0.6424155124226305')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -3.245621587698742')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.016', ' effect_size: -0.7595750417999285')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.035', ' effect_size: -0.6663449677574423')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.791621707253368')","('killed: True', 'Sector number: 2', ' p_value: 0.009', ' effect_size: 0.8264009129323419')","('killed: True', 'Sector number: 1', ' p_value: 0.01', ' effect_size: 0.8145594154352576')","('killed: True', 'Sector number: 2', ' p_value: 0.022', ' effect_size: -0.7236723227678095')","('killed: True', 'Sector number: 6', ' p_value: 0.005', ' effect_size: 0.8889208648802099')","('killed: True', 'Sector number: 0', ' p_value: 0.012', ' effect_size: -0.7976400369192155')"
13,udacity_change_label_mutated0_MP_12.5,"('killed: True', 'Sector number: 10', ' p_value: 0.04', ' effect_size: -0.6509028152105564')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.004', ' effect_size: -0.9167755905341161')","('killed: True', 'Sector number: 10', ' p_value: 0.013', ' effect_size: -0.7868998466380149')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.2586552186446927')","('killed: True', 'Sector number: 2', ' p_value: 0.021', ' effect_size: -0.7315973534694318')","('killed: True', 'Sector number: 17', ' p_value: 0.001', ' effect_size: -1.0957795456788548')","('killed: True', 'Sector number: 3', ' p_value: 0.012', ' effect_size: 0.7964598005229582')","('killed: True', 'Sector number: 19', ' p_value: 0.039', ' effect_size: -0.6513065727394891')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1088284085237419')","('killed: True', 'Sector number: 12', ' p_value: 0.03', ' effect_size: -0.6862240646077364')","('killed: True', 'Sector number: 9', ' p_value: 0.047', ' effect_size: -0.6284255420951471')","('killed: True', 'Sector number: 10', ' p_value: 0.006', ' effect_size: -0.8777626577507605')","('killed: True', 'Sector number: 3', ' p_value: 0.031', ' effect_size: 0.6839685011112225')","('killed: True', 'Sector number: 0', ' p_value: 0.024', ' effect_size: 0.7132643985669429')","('killed: True', 'Sector number: 20', ' p_value: 0.014', ' effect_size: 0.7810725220066136')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.4774757150270856')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9819637609753588')"
14,udacity_change_label_mutated0_MP_15.62,"('killed: True', 'Sector number: 10', ' p_value: 0.023', ' effect_size: -0.7199066068102326')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.005', ' effect_size: -0.8961467452230106')","('killed: True', 'Sector number: 10', ' p_value: 0.007', ' effect_size: -0.8520120467384121')","('killed: True', 'Sector number: 0', ' p_value: 0.033', ' effect_size: 0.6738679342435553')","('killed: True', 'Sector number: 15', ' p_value: 0.021', ' effect_size: -0.7302827051308116')","('killed: True', 'Sector number: 3', ' p_value: 0.015', ' effect_size: -0.768107325271515')","('killed: True', 'Sector number: 18', ' p_value: 0.043', ' effect_size: 0.6409662212873896')","('killed: True', 'Sector number: 17', ' p_value: 0.036', ' effect_size: -0.6613580368700076')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.037', ' effect_size: -0.6610523489497414')","('killed: True', 'Sector number: 1', ' p_value: 0.038', ' effect_size: -0.6553371004019486')","('killed: True', 'Sector number: 2', ' p_value: 0.037', ' effect_size: -0.6583040103953799')","('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8459333081462416')","('killed: True', 'Sector number: 2', ' p_value: 0.026', ' effect_size: 0.7023680888105727')","('killed: True', 'Sector number: 15', ' p_value: 0.007', ' effect_size: 0.8545898549916816')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.603622266857563')","('killed: True', 'Sector number: 2', ' p_value: 0.032', ' effect_size: 0.6785839332563041')","('killed: True', 'Sector number: 2', ' p_value: 0.013', ' effect_size: -0.78145803095375')"
15,udacity_change_label_mutated0_MP_25.0,"('killed: True', 'Sector number: 12', ' p_value: 0.025', ' effect_size: -0.7111776338391188')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 13', ' p_value: 0.049', ' effect_size: -0.621561751941242')","('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: 0.9924667507178015')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 19', ' p_value: 0.038', ' effect_size: 0.6562976277077296')","('killed: True', 'Sector number: 7', ' p_value: 0.01', ' effect_size: -0.8126084233524565')",Not killed by this metric,"('killed: True', 'Sector number: 12', ' p_value: 0.045', ' effect_size: -0.632599704287918')","('killed: True', 'Sector number: 13', ' p_value: 0.022', ' effect_size: -0.7216363567594656')","('killed: True', 'Sector number: 11', ' p_value: 0.011', ' effect_size: -0.7995177963339122')","('killed: True', 'Sector number: 16', ' p_value: 0.045', ' effect_size: 0.6341685679777382')","('killed: True', 'Sector number: 2', ' p_value: 0.019', ' effect_size: 0.744099378488513')","('killed: True', 'Sector number: 10', ' p_value: 0.045', ' effect_size: 0.6327344666282466')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.4628103082244726')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.049', ' effect_size: -0.62261458387311')"
16,udacity_change_label_mutated0_MP_37.5,"('killed: True', 'Sector number: 16', ' p_value: 0.037', ' effect_size: -0.6589091952733771')","('killed: True', 'Sector number: 1', ' p_value: 0.016', ' effect_size: 0.7635990458154333')","('killed: True', 'Sector number: 1', ' p_value: 0.011', ' effect_size: -0.8039014803767711')","('killed: True', 'Sector number: 10', ' p_value: 0.009', ' effect_size: -0.8254474494348679')","('killed: True', 'Sector number: 0', ' p_value: 0.007', ' effect_size: 0.8554713255363986')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.1206797131269945')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.012', ' effect_size: 0.7964599823173355')","('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: -0.9741630003763314')","('killed: True', 'Sector number: 3', ' p_value: 0.044', ' effect_size: -0.6358250458743064')","('killed: True', 'Sector number: 3', ' p_value: 0.036', ' effect_size: -0.6617459996581577')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.016', ' effect_size: -0.7590068892566184')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8649782638899793')","('killed: True', 'Sector number: 2', ' p_value: 0.03', ' effect_size: 0.6879421834027433')","('killed: True', 'Sector number: 10', ' p_value: 0.016', ' effect_size: 0.7639163901209937')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.2123915630887971')","('killed: True', 'Sector number: 12', ' p_value: 0.03', ' effect_size: 0.6860625233318545')","('killed: True', 'Sector number: 3', ' p_value: 0.007', ' effect_size: -0.8578317934418357')"
17,udacity_change_label_mutated0_MP_43.75,"('killed: True', 'Sector number: 12', ' p_value: 0.036', ' effect_size: -0.6616324048088217')",Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: -1.0858173062357401')","('killed: True', 'Sector number: 11', ' p_value: 0.049', ' effect_size: -0.62304271784638')","('killed: True', 'Sector number: 0', ' p_value: 0.014', ' effect_size: 0.7765947819914948')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.3032405403270177')","('killed: True', 'Sector number: 3', ' p_value: 0.013', ' effect_size: -0.7823822847818505')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: 1.0134575120716194')","('killed: True', 'Sector number: 0', ' p_value: 0.011', ' effect_size: -0.8036660385869521')","('killed: True', 'Sector number: 9', ' p_value: 0.007', ' effect_size: -0.8532189678690385')","('killed: True', 'Sector number: 12', ' p_value: 0.002', ' effect_size: -0.9837593676481857')","('killed: True', 'Sector number: 3', ' p_value: 0.035', ' effect_size: -0.6651242613913184')","('killed: True', 'Sector number: 14', ' p_value: 0.044', ' effect_size: -0.6382692200621988')","('killed: True', 'Sector number: 2', ' p_value: 0.002', ' effect_size: 0.9822343830292877')","('killed: True', 'Sector number: 15', ' p_value: 0.03', ' effect_size: 0.6862176225982297')","('killed: True', 'Sector number: 10', ' p_value: 0.014', ' effect_size: 0.7738404368370622')","('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.0634751381640064')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.011', ' effect_size: -0.7999607171490868')"
18,udacity_change_label_mutated0_MP_46.88,"('killed: True', 'Sector number: 20', ' p_value: 0.006', ' effect_size: -0.8661477362862764')",Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: -0.9577542476553987')","('killed: True', 'Sector number: 16', ' p_value: 0.045', ' effect_size: -0.6328866262832765')","('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: 1.0559860786046915')","('killed: True', 'Sector number: 0', ' p_value: 0.038', ' effect_size: -0.6552746525653843')","('killed: True', 'Sector number: 14', ' p_value: 0.013', ' effect_size: -0.7824932075515202')","('killed: True', 'Sector number: 3', ' p_value: 0.041', ' effect_size: 0.6473880592596')","('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: -1.0252040285038926')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.034', ' effect_size: -0.6720294507977014')","('killed: True', 'Sector number: 10', ' p_value: 0.015', ' effect_size: -0.7716210762978774')","('killed: True', 'Sector number: 14', ' p_value: 0.006', ' effect_size: -0.8733127174916747')","('killed: True', 'Sector number: 16', ' p_value: 0.012', ' effect_size: 0.7907638468259025')","('killed: True', 'Sector number: 2', ' p_value: 0.008', ' effect_size: 0.8441161955307948')","('killed: True', 'Sector number: 10', ' p_value: 0.043', ' effect_size: 0.6397887408937251')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3049131260378264')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.01', ' effect_size: -0.816487512211362')"
19,udacity_change_label_mutated0_MP_50.0,"('killed: True', 'Sector number: 15', ' p_value: 0.029', ' effect_size: -0.6915234206835932')","('killed: True', 'Sector number: 23', ' p_value: 0.026', ' effect_size: 0.7061452563181173')","('killed: True', 'Sector number: 0', ' p_value: 0.024', ' effect_size: -0.713155549098424')","('killed: True', 'Sector number: 10', ' p_value: 0.019', ' effect_size: -0.7444269561684137')","('killed: True', 'Sector number: 0', ' p_value: 0.003', ' effect_size: 0.9450550149339773')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.4505551945946196')","('killed: True', 'Sector number: 16', ' p_value: 0.049', ' effect_size: -0.6238316517758682')","('killed: True', 'Sector number: 9', ' p_value: 0.009', ' effect_size: 0.8304446121635526')","('killed: True', 'Sector number: 0', ' p_value: 0.006', ' effect_size: -0.8768805535826298')","('killed: True', 'Sector number: 9', ' p_value: 0.028', ' effect_size: -0.6969582575042911')","('killed: True', 'Sector number: 12', ' p_value: 0.04', ' effect_size: -0.6500027334950839')","('killed: True', 'Sector number: 13', ' p_value: 0.044', ' effect_size: -0.6371992093023569')","('killed: True', 'Sector number: 2', ' p_value: 0.031', ' effect_size: -0.6831639246002914')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0130834707194813')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.9333076843180332')","('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8563980162787159')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3773377620850789')","('killed: True', 'Sector number: 6', ' p_value: 0.005', ' effect_size: 0.8899371802598236')","('killed: True', 'Sector number: 2', ' p_value: 0.002', ' effect_size: -0.9578506998522812')"
20,udacity_change_learning_rate_mutated0_MP_False_1e-05,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1840429104143693')","('killed: True', 'Sector number: 1', ' p_value: 0.013', ' effect_size: 0.7824163253016605')","('killed: True', 'Sector number: 16', ' p_value: 0.003', ' effect_size: -0.950771583484897')","('killed: True', 'Sector number: 3', ' p_value: 0.024', ' effect_size: -0.7158826726251705')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.4907662735651839')","('killed: True', 'Sector number: 16', ' p_value: 0.006', ' effect_size: -0.8670952529825473')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: -0.8408369936087964')","('killed: True', 'Sector number: 0', ' p_value: 0.045', ' effect_size: 0.6352348220600997')","('killed: True', 'Sector number: 16', ' p_value: 0.031', ' effect_size: -0.6822330441237789')","('killed: True', 'Sector number: 0', ' p_value: 0.014', ' effect_size: -0.7758736847960945')","('killed: True', 'Sector number: 19', ' p_value: 0.043', ' effect_size: -0.64032551976013')","('killed: True', 'Sector number: 0', ' p_value: 0.042', ' effect_size: -0.6427910822440089')","('killed: True', 'Sector number: 4', ' p_value: 0.002', ' effect_size: -0.9592860650133695')","('killed: True', 'Sector number: 6', ' p_value: 0.025', ' effect_size: 0.7094362022410907')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8626496565969975')","('killed: True', 'Sector number: 16', ' p_value: 0.002', ' effect_size: 0.9601431202946462')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9872916836821263')","('killed: True', 'Sector number: 1', ' p_value: 0.045', ' effect_size: 0.6352263714019004')","('killed: True', 'Sector number: 0', ' p_value: 0.003', ' effect_size: -0.9498174443027109')"
21,udacity_change_learning_rate_mutated0_MP_False_6e-05,"('killed: True', 'Sector number: 24', ' p_value: 0.023', ' effect_size: -0.720036640617367')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.9309569840762318')","('killed: True', 'Sector number: 2', ' p_value: 0.008', ' effect_size: -0.8365723281099241')","('killed: True', 'Sector number: 20', ' p_value: 0.029', ' effect_size: -0.6897755157371281')","('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: 0.998502414402248')","('killed: True', 'Sector number: 15', ' p_value: 0.015', ' effect_size: -0.7729989621546315')","('killed: True', 'Sector number: 1', ' p_value: 0.007', ' effect_size: -0.8527430445342953')","('killed: True', 'Sector number: 5', ' p_value: 0.023', ' effect_size: 0.7173638815834829')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.039', ' effect_size: -0.6534541465156138')","('killed: True', 'Sector number: 12', ' p_value: 0.008', ' effect_size: -0.8360881281698107')",Not killed by this metric,"('killed: True', 'Sector number: 20', ' p_value: 0.001', ' effect_size: -1.0120718951880847')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8715743956842769')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.4098472733925502')","('killed: True', 'Sector number: 4', ' p_value: 0.01', ' effect_size: 0.819316360685881')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9993720699218922')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.936189459191698')","('killed: True', 'Sector number: 2', ' p_value: 0.026', ' effect_size: -0.7043305614490334')"
22,udacity_change_loss_function_mutated0_MP_logcosh,"('killed: True', 'Sector number: 10', ' p_value: 0.038', ' effect_size: -0.6561626344792878')","('killed: True', 'Sector number: 2', ' p_value: 0.013', ' effect_size: 0.7843014425943654')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: -1.3360834085972628')","('killed: True', 'Sector number: 10', ' p_value: 0.01', ' effect_size: -0.8194544968412186')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8652714564338407')","('killed: True', 'Sector number: 17', ' p_value: 0.038', ' effect_size: -0.6552788253129208')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.006', ' effect_size: 0.8623573816982208')","('killed: True', 'Sector number: 2', ' p_value: 0.032', ' effect_size: -0.6783374847998178')","('killed: True', 'Sector number: 3', ' p_value: 0.015', ' effect_size: -0.7704341555126486')","('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.186719495486928')","('killed: True', 'Sector number: 3', ' p_value: 0.041', ' effect_size: -0.6466011484662197')","('killed: True', 'Sector number: 10', ' p_value: 0.013', ' effect_size: -0.7897119519160498')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0395354210729986')","('killed: True', 'Sector number: 2', ' p_value: 0.008', ' effect_size: 0.8350291698079068')","('killed: True', 'Sector number: 4', ' p_value: 0.029', ' effect_size: 0.6905602866015501')","('killed: True', 'Sector number: 3', ' p_value: 0.036', ' effect_size: -0.6628001548825033')","('killed: True', 'Sector number: 1', ' p_value: 0.035', ' effect_size: 0.6666354685361339')","('killed: True', 'Sector number: 2', ' p_value: 0.022', ' effect_size: -0.7220416987813085')"
23,udacity_change_loss_function_mutated0_MP_mean_absolute_error,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.2145606317629842')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.045', ' effect_size: -0.6334663482590984')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.5815449031507018')","('killed: True', 'Sector number: 0', ' p_value: 0.031', ' effect_size: 0.6838094652481465')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.4334977763191277')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.3789939714460206')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.279457047362504')","('killed: True', 'Sector number: 0', ' p_value: 0.002', ' effect_size: -0.9717998234654732')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.016996142094676')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: -0.8425711892648956')",Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.032', ' effect_size: 0.6763346562315559')","('killed: True', 'Sector number: 16', ' p_value: 0.025', ' effect_size: 0.709541054853775')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -1.0020320432984022')","('killed: True', 'Sector number: 1', ' p_value: 0.007', ' effect_size: 0.8528996817020125')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.9885438498756138')"
24,udacity_change_optimisation_function_mutated0_MP_adagrad,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.8467267457636805')","('killed: True', 'Sector number: 4', ' p_value: 0.0', ' effect_size: 1.7370673907998055')","('killed: True', 'Sector number: 16', ' p_value: 0.035', ' effect_size: -0.6672010984287774')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.2202744652151467')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 2.046468602476335')","('killed: True', 'Sector number: 15', ' p_value: 0.0', ' effect_size: -1.5435645600724544')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.7477061961803164')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 2.336872656533943')","('killed: True', 'Sector number: 15', ' p_value: 0.017', ' effect_size: -0.7561093542963683')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.6517362683084906')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.195890613474119')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.505308560858345')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.7521768058899334')","('killed: True', 'Sector number: 6', ' p_value: 0.0', ' effect_size: 1.5164971458665746')","('killed: True', 'Sector number: 2', ' p_value: 0.032', ' effect_size: 0.6776199224687842')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: 1.0597291000880424')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.2291034772963663')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.7867806886808193')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -3.202292097861936')"
25,udacity_change_weights_initialisation_mutated0_MP_constant_4,"('killed: True', 'Sector number: 3', ' p_value: 0.049', ' effect_size: -0.6220124105850021')",Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.022', ' effect_size: -0.7246515798015849')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.02', ' effect_size: 0.735975896486729')","('killed: True', 'Sector number: 0', ' p_value: 0.028', ' effect_size: -0.6938272254321042')","('killed: True', 'Sector number: 20', ' p_value: 0.005', ' effect_size: -0.8874012298458074')","('killed: True', 'Sector number: 3', ' p_value: 0.024', ' effect_size: 0.7113196126522158')",Not killed by this metric,"('killed: True', 'Sector number: 20', ' p_value: 0.014', ' effect_size: -0.7772453571491561')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9685500130763434')","('killed: True', 'Sector number: 0', ' p_value: 0.045', ' effect_size: -0.6325799636399473')","('killed: True', 'Sector number: 2', ' p_value: 0.02', ' effect_size: 0.7374033768794068')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.075939160869845')","('killed: True', 'Sector number: 15', ' p_value: 0.032', ' effect_size: 0.678312887333985')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.223997837785994')","('killed: True', 'Sector number: 15', ' p_value: 0.016', ' effect_size: 0.7604472311671886')","('killed: True', 'Sector number: 15', ' p_value: 0.002', ' effect_size: -0.9839681629949544')"
26,udacity_change_weights_initialisation_mutated0_MP_glorot_normal_3,"('killed: True', 'Sector number: 9', ' p_value: 0.027', ' effect_size: -0.7008837596010451')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.046', ' effect_size: -0.6306756527327865')","('killed: True', 'Sector number: 9', ' p_value: 0.048', ' effect_size: -0.6256515895874868')","('killed: True', 'Sector number: 0', ' p_value: 0.01', ' effect_size: 0.8119117954100599')","('killed: True', 'Sector number: 10', ' p_value: 0.045', ' effect_size: -0.6352270679259211')",Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 11', ' p_value: 0.017', ' effect_size: -0.7573141824220077')","('killed: True', 'Sector number: 10', ' p_value: 0.02', ' effect_size: -0.7356410719591482')","('killed: True', 'Sector number: 11', ' p_value: 0.009', ' effect_size: -0.8273140641300345')","('killed: True', 'Sector number: 10', ' p_value: 0.0', ' effect_size: -1.4324598067806604')","('killed: True', 'Sector number: 16', ' p_value: 0.048', ' effect_size: 0.624256669050002')","('killed: True', 'Sector number: 0', ' p_value: 0.034', ' effect_size: 0.6721893513104833')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.005', ' effect_size: -0.8841100819942643')","('killed: True', 'Sector number: 9', ' p_value: 0.026', ' effect_size: 0.7018653620325269')","('killed: True', 'Sector number: 15', ' p_value: 0.018', ' effect_size: -0.7460429618935961')"
27,udacity_change_weights_initialisation_mutated0_MP_glorot_uniform_3,"('killed: True', 'Sector number: 10', ' p_value: 0.036', ' effect_size: -0.6642200796922392')","('killed: True', 'Sector number: 2', ' p_value: 0.015', ' effect_size: 0.7696648393436964')","('killed: True', 'Sector number: 2', ' p_value: 0.005', ' effect_size: -0.8781608842621972')","('killed: True', 'Sector number: 10', ' p_value: 0.003', ' effect_size: -0.952077404479907')","('killed: True', 'Sector number: 1', ' p_value: 0.006', ' effect_size: 0.8710590848666422')","('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: -0.796824967844227')","('killed: True', 'Sector number: 1', ' p_value: 0.029', ' effect_size: -0.6888478376024423')","('killed: True', 'Sector number: 3', ' p_value: 0.006', ' effect_size: 0.8719678973728483')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.009', ' effect_size: -0.8230613495538711')","('killed: True', 'Sector number: 3', ' p_value: 0.022', ' effect_size: -0.721852453720752')","('killed: True', 'Sector number: 10', ' p_value: 0.043', ' effect_size: -0.639029723306854')","('killed: True', 'Sector number: 0', ' p_value: 0.01', ' effect_size: -0.810319334637614')","('killed: True', 'Sector number: 2', ' p_value: 0.017', ' effect_size: 0.7545633649835738')","('killed: True', 'Sector number: 2', ' p_value: 0.027', ' effect_size: 0.6977052459288376')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.0326956090302217')","('killed: True', 'Sector number: 2', ' p_value: 0.043', ' effect_size: 0.6399487920461661')","('killed: True', 'Sector number: 15', ' p_value: 0.02', ' effect_size: -0.7333676510131389')"
28,udacity_change_weights_initialisation_mutated0_MP_he_normal_3,"('killed: True', 'Sector number: 20', ' p_value: 0.0', ' effect_size: -1.2115730663114301')","('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: 0.7937460336825496')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.035', ' effect_size: -0.6674431792057918')","('killed: True', 'Sector number: 0', ' p_value: 0.014', ' effect_size: 0.7731429904259922')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 9', ' p_value: 0.019', ' effect_size: 0.7428296859172063')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.3509064593945272')","('killed: True', 'Sector number: 20', ' p_value: 0.005', ' effect_size: -0.8900990920130508')","('killed: True', 'Sector number: 10', ' p_value: 0.048', ' effect_size: -0.625495334875337')","('killed: True', 'Sector number: 6', ' p_value: 0.032', ' effect_size: 0.6793232484984697')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0298283333301421')",Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric
29,udacity_change_weights_initialisation_mutated0_MP_identity_4,"('killed: True', 'Sector number: 12', ' p_value: 0.01', ' effect_size: -0.8179174538868317')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: -0.9355778285251746')","('killed: True', 'Sector number: 10', ' p_value: 0.007', ' effect_size: -0.8500131975184')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.1062896969444898')","('killed: True', 'Sector number: 15', ' p_value: 0.029', ' effect_size: -0.6884632217771661')",Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.5256954467200459')","('killed: True', 'Sector number: 10', ' p_value: 0.017', ' effect_size: -0.7543287088817798')","('killed: True', 'Sector number: 10', ' p_value: 0.019', ' effect_size: -0.7440127349000867')","('killed: True', 'Sector number: 16', ' p_value: 0.035', ' effect_size: 0.6674209972925139')","('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: 0.9371767971183578')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: 1.0520573254957377')","('killed: True', 'Sector number: 15', ' p_value: 0.007', ' effect_size: -0.8458888474527275')"
30,udacity_change_weights_initialisation_mutated0_MP_lecun_uniform_4,"('killed: True', 'Sector number: 12', ' p_value: 0.006', ' effect_size: -0.8758486472158228')","('killed: True', 'Sector number: 1', ' p_value: 0.024', ' effect_size: 0.7132961483133937')","('killed: True', 'Sector number: 2', ' p_value: 0.041', ' effect_size: -0.6452442990461551')","('killed: True', 'Sector number: 11', ' p_value: 0.019', ' effect_size: -0.743239040138051')","('killed: True', 'Sector number: 1', ' p_value: 0.017', ' effect_size: 0.7574994909809489')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.029', ' effect_size: -0.6917486110649267')","('killed: True', 'Sector number: 5', ' p_value: 0.018', ' effect_size: 0.7451942691246651')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.07263097535511')","('killed: True', 'Sector number: 13', ' p_value: 0.024', ' effect_size: -0.7132150477685689')","('killed: True', 'Sector number: 10', ' p_value: 0.047', ' effect_size: -0.6271812292502581')","('killed: True', 'Sector number: 6', ' p_value: 0.041', ' effect_size: 0.6454105746719434')","('killed: True', 'Sector number: 2', ' p_value: 0.015', ' effect_size: 0.7671468519326209')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.34173415282101')",Not killed by this metric,Not killed by this metric
31,udacity_change_weights_initialisation_mutated0_MP_orthogonal_4,"('killed: True', 'Sector number: 10', ' p_value: 0.02', ' effect_size: -0.7365865963770257')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.014', ' effect_size: -0.7807911693234801')","('killed: True', 'Sector number: 10', ' p_value: 0.012', ' effect_size: -0.7979341438892046')","('killed: True', 'Sector number: 0', ' p_value: 0.002', ' effect_size: 0.9659446540266005')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.006', ' effect_size: 0.8653490653316799')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1499945750856764')","('killed: True', 'Sector number: 13', ' p_value: 0.012', ' effect_size: -0.7962918618379026')","('killed: True', 'Sector number: 10', ' p_value: 0.002', ' effect_size: -0.9597572026742861')","('killed: True', 'Sector number: 2', ' p_value: 0.036', ' effect_size: 0.6621370858412599')","('killed: True', 'Sector number: 2', ' p_value: 0.008', ' effect_size: 0.8426093810131231')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3142543398082926')",Not killed by this metric,Not killed by this metric
32,udacity_change_weights_initialisation_mutated0_MP_random_normal_4,"('killed: True', 'Sector number: 12', ' p_value: 0.049', ' effect_size: -0.6213155137379294')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.014', ' effect_size: -0.7799596508681982')","('killed: True', 'Sector number: 16', ' p_value: 0.04', ' effect_size: -0.6498862440271176')","('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: 0.9562625470137033')","('killed: True', 'Sector number: 16', ' p_value: 0.036', ' effect_size: -0.6629174872813716')","('killed: True', 'Sector number: 14', ' p_value: 0.009', ' effect_size: -0.8202562435239688')","('killed: True', 'Sector number: 3', ' p_value: 0.004', ' effect_size: 0.9025169243390948')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.005', ' effect_size: -0.880109848257267')","('killed: True', 'Sector number: 3', ' p_value: 0.031', ' effect_size: -0.6810355069521573')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.045', ' effect_size: -0.6350673700288664')","('killed: True', 'Sector number: 6', ' p_value: 0.038', ' effect_size: 0.6549470186448841')","('killed: True', 'Sector number: 15', ' p_value: 0.014', ' effect_size: 0.7779553754811597')","('killed: True', 'Sector number: 20', ' p_value: 0.048', ' effect_size: 0.625447345529256')","('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.0614620310392882')","('killed: True', 'Sector number: 15', ' p_value: 0.012', ' effect_size: 0.7927075775123537')","('killed: True', 'Sector number: 15', ' p_value: 0.007', ' effect_size: -0.8579134633933875')"
33,udacity_change_weights_initialisation_mutated0_MP_random_uniform_4,"('killed: True', 'Sector number: 10', ' p_value: 0.049', ' effect_size: -0.621335264629918')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.004', ' effect_size: -0.9152662781469716')","('killed: True', 'Sector number: 10', ' p_value: 0.001', ' effect_size: -1.03019860933908')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: 0.9184095495239881')","('killed: True', 'Sector number: 15', ' p_value: 0.027', ' effect_size: -0.6993468260301312')","('killed: True', 'Sector number: 21', ' p_value: 0.037', ' effect_size: -0.6608382703206586')",Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.338612790626709')","('killed: True', 'Sector number: 13', ' p_value: 0.001', ' effect_size: -1.0327328609764557')","('killed: True', 'Sector number: 10', ' p_value: 0.001', ' effect_size: -1.1004280998780651')","('killed: True', 'Sector number: 16', ' p_value: 0.041', ' effect_size: 0.6452744299737787')","('killed: True', 'Sector number: 15', ' p_value: 0.005', ' effect_size: 0.8896358884103613')","('killed: True', 'Sector number: 15', ' p_value: 0.029', ' effect_size: 0.6917247774434602')","('killed: True', 'Sector number: 15', ' p_value: 0.006', ' effect_size: -0.87148958994056')","('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: 0.9862849929986254')","('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: -0.9516031681421447')"
34,udacity_change_weights_initialisation_mutated0_MP_variance_scaling_4,"('killed: True', 'Sector number: 12', ' p_value: 0.031', ' effect_size: -0.6819725854930412')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: -0.7953210712576914')","('killed: True', 'Sector number: 15', ' p_value: 0.008', ' effect_size: -0.8331343033063964')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.3182831154924464')",Not killed by this metric,"('killed: True', 'Sector number: 21', ' p_value: 0.02', ' effect_size: -0.7353964756655785')","('killed: True', 'Sector number: 3', ' p_value: 0.021', ' effect_size: 0.7279726332480442')",Not killed by this metric,"('killed: True', 'Sector number: 26', ' p_value: 0.004', ' effect_size: -0.9027218714376358')","('killed: True', 'Sector number: 3', ' p_value: 0.018', ' effect_size: -0.7513314007741924')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.03', ' effect_size: -0.6845090145626699')","('killed: True', 'Sector number: 2', ' p_value: 0.047', ' effect_size: 0.6293974013467057')","('killed: True', 'Sector number: 2', ' p_value: 0.036', ' effect_size: 0.6635761605768309')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.2794400241668018')","('killed: True', 'Sector number: 2', ' p_value: 0.044', ' effect_size: 0.6362853070452821')","('killed: True', 'Sector number: 2', ' p_value: 0.045', ' effect_size: -0.6347220957776322')"
35,udacity_change_weights_initialisation_mutated0_MP_zeros_5,"('killed: True', 'Sector number: 12', ' p_value: 0.043', ' effect_size: -0.6397546220339455')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.024', ' effect_size: -0.7132709044821768')","('killed: True', 'Sector number: 11', ' p_value: 0.03', ' effect_size: -0.6844250476039218')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.2772865909159936')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.012', ' effect_size: 0.7928812281831341')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: -0.8266295986450897')","('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.53855182442595')","('killed: True', 'Sector number: 10', ' p_value: 0.026', ' effect_size: -0.7044318074763299')","('killed: True', 'Sector number: 14', ' p_value: 0.005', ' effect_size: -0.8901744821777149')","('killed: True', 'Sector number: 16', ' p_value: 0.016', ' effect_size: 0.7647166578999199')","('killed: True', 'Sector number: 2', ' p_value: 0.036', ' effect_size: 0.6640943398794176')","('killed: True', 'Sector number: 20', ' p_value: 0.046', ' effect_size: 0.630981464208805')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.22910845677724')","('killed: True', 'Sector number: 15', ' p_value: 0.038', ' effect_size: 0.6557641596465169')","('killed: True', 'Sector number: 15', ' p_value: 0.015', ' effect_size: -0.771521541370298')"
36,udacity_delete_training_data_mutated0_MP_18.57,"('killed: True', 'Sector number: 15', ' p_value: 0.018', ' effect_size: -0.7452415682934593')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 11', ' p_value: 0.031', ' effect_size: -0.6809712223428949')","('killed: True', 'Sector number: 0', ' p_value: 0.01', ' effect_size: 0.816018372572895')",Not killed by this metric,"('killed: True', 'Sector number: 20', ' p_value: 0.011', ' effect_size: -0.8059146528832823')","('killed: True', 'Sector number: 3', ' p_value: 0.025', ' effect_size: 0.7096623954962132')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 12', ' p_value: 0.037', ' effect_size: -0.6584101753148769')","('killed: True', 'Sector number: 21', ' p_value: 0.042', ' effect_size: -0.6438109137241373')","('killed: True', 'Sector number: 10', ' p_value: 0.024', ' effect_size: -0.7144374446082291')","('killed: True', 'Sector number: 6', ' p_value: 0.001', ' effect_size: 1.0388888010174755')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1093849267092817')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.049', ' effect_size: -0.6230727433798998')"
37,udacity_delete_training_data_mutated0_MP_30.93,"('killed: True', 'Sector number: 19', ' p_value: 0.043', ' effect_size: -0.6409782493278237')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.042', ' effect_size: -0.6436473790843695')","('killed: True', 'Sector number: 11', ' p_value: 0.005', ' effect_size: -0.8847768412604347')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: 0.8341570761625504')","('killed: True', 'Sector number: 0', ' p_value: 0.031', ' effect_size: -0.6813621853772246')","('killed: True', 'Sector number: 20', ' p_value: 0.001', ' effect_size: -1.0883176182701098')","('killed: True', 'Sector number: 16', ' p_value: 0.008', ' effect_size: 0.8357525939315475')","('killed: True', 'Sector number: 24', ' p_value: 0.046', ' effect_size: -0.6309152047364079')","('killed: True', 'Sector number: 26', ' p_value: 0.035', ' effect_size: -0.6681644676115832')","('killed: True', 'Sector number: 12', ' p_value: 0.01', ' effect_size: -0.8143269539711624')","('killed: True', 'Sector number: 13', ' p_value: 0.019', ' effect_size: -0.7424743954060882')","('killed: True', 'Sector number: 12', ' p_value: 0.047', ' effect_size: -0.629364141475774')","('killed: True', 'Sector number: 16', ' p_value: 0.001', ' effect_size: 1.0323453363408128')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0640516220513188')","('killed: True', 'Sector number: 15', ' p_value: 0.009', ' effect_size: 0.8268189306073811')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1752891722790633')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: 1.0169314773611877')","('killed: True', 'Sector number: 15', ' p_value: 0.0', ' effect_size: -1.133050882880901')"
38,udacity_delete_training_data_mutated0_MP_37.12,"('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.0820820714859087')",Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.018', ' effect_size: -0.7499578657109978')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.0855438182587784')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.3979362477233295')","('killed: True', 'Sector number: 0', ' p_value: 0.006', ' effect_size: -0.8641978746907567')","('killed: True', 'Sector number: 20', ' p_value: 0.003', ' effect_size: -0.926394413950699')","('killed: True', 'Sector number: 9', ' p_value: 0.018', ' effect_size: 0.7511263300349503')","('killed: True', 'Sector number: 26', ' p_value: 0.007', ' effect_size: -0.859087892976755')","('killed: True', 'Sector number: 25', ' p_value: 0.014', ' effect_size: -0.7759582892025286')","('killed: True', 'Sector number: 12', ' p_value: 0.014', ' effect_size: -0.779790470366229')","('killed: True', 'Sector number: 15', ' p_value: 0.025', ' effect_size: -0.7076596370945879')","('killed: True', 'Sector number: 0', ' p_value: 0.014', ' effect_size: -0.7750253234031756')","('killed: True', 'Sector number: 16', ' p_value: 0.007', ' effect_size: 0.8522936915515058')","('killed: True', 'Sector number: 0', ' p_value: 0.038', ' effect_size: 0.655656569877084')","('killed: True', 'Sector number: 10', ' p_value: 0.029', ' effect_size: 0.6923480263133901')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.304272741196478')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.042', ' effect_size: -0.6441978601550882')"
39,udacity_delete_training_data_mutated0_MP_49.5,"('killed: True', 'Sector number: 23', ' p_value: 0.027', ' effect_size: -0.6980059591303983')","('killed: True', 'Sector number: 1', ' p_value: 0.046', ' effect_size: 0.6300499193073538')","('killed: True', 'Sector number: 16', ' p_value: 0.009', ' effect_size: -0.8291789517504873')","('killed: True', 'Sector number: 23', ' p_value: 0.021', ' effect_size: -0.7322985489714375')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.1368039274651736')","('killed: True', 'Sector number: 16', ' p_value: 0.025', ' effect_size: -0.7097962247756805')","('killed: True', 'Sector number: 20', ' p_value: 0.002', ' effect_size: -0.9949890203535138')","('killed: True', 'Sector number: 0', ' p_value: 0.04', ' effect_size: 0.6501596434972139')",Not killed by this metric,"('killed: True', 'Sector number: 26', ' p_value: 0.003', ' effect_size: -0.9375121425349723')",Not killed by this metric,"('killed: True', 'Sector number: 24', ' p_value: 0.01', ' effect_size: -0.8096111898102464')","('killed: True', 'Sector number: 0', ' p_value: 0.042', ' effect_size: -0.6424599784755656')","('killed: True', 'Sector number: 16', ' p_value: 0.006', ' effect_size: 0.8766108271014871')","('killed: True', 'Sector number: 2', ' p_value: 0.004', ' effect_size: 0.9139045369332348')","('killed: True', 'Sector number: 15', ' p_value: 0.039', ' effect_size: 0.6521177026711111')","('killed: True', 'Sector number: 3', ' p_value: 0.003', ' effect_size: -0.9343711787323129')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.036', ' effect_size: -0.6631191367086818')"
40,udacity_delete_training_data_mutated0_MP_6.19,"('killed: True', 'Sector number: 11', ' p_value: 0.035', ' effect_size: -0.6682415872913738')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0933050652415441')","('killed: True', 'Sector number: 1', ' p_value: 0.026', ' effect_size: -0.7042334511284499')","('killed: True', 'Sector number: 10', ' p_value: 0.006', ' effect_size: -0.8706721945998024')","('killed: True', 'Sector number: 1', ' p_value: 0.034', ' effect_size: 0.6688335975536231')","('killed: True', 'Sector number: 1', ' p_value: 0.003', ' effect_size: -0.9303328115310449')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: -1.1154536687435799')","('killed: True', 'Sector number: 16', ' p_value: 0.011', ' effect_size: 0.8013438860643655')","('killed: True', 'Sector number: 19', ' p_value: 0.026', ' effect_size: -0.7032718348737207')",Not killed by this metric,"('killed: True', 'Sector number: 12', ' p_value: 0.005', ' effect_size: -0.8793597130938023')","('killed: True', 'Sector number: 11', ' p_value: 0.004', ' effect_size: -0.9126298635377796')","('killed: True', 'Sector number: 10', ' p_value: 0.004', ' effect_size: -0.9174475299558076')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.1266033838654572')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.533383986171786')","('killed: True', 'Sector number: 4', ' p_value: 0.024', ' effect_size: 0.7136648573136258')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.688096349813493')","('killed: True', 'Sector number: 2', ' p_value: 0.002', ' effect_size: 1.0008639101446553')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: -0.939572640091183')"
41,udacity_delete_training_data_mutated0_MP_9.29,"('killed: True', 'Sector number: 16', ' p_value: 0.0', ' effect_size: -1.4442044171061243')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.1080067016325177')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: -1.0166869671755085')","('killed: True', 'Sector number: 10', ' p_value: 0.015', ' effect_size: -0.7707642659780475')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.788081802380516')","('killed: True', 'Sector number: 16', ' p_value: 0.0', ' effect_size: -1.1071261664939358')","('killed: True', 'Sector number: 14', ' p_value: 0.009', ' effect_size: -0.828101740175187')","('killed: True', 'Sector number: 3', ' p_value: 0.01', ' effect_size: 0.809827174401963')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.036', ' effect_size: -0.6625171927222312')","('killed: True', 'Sector number: 16', ' p_value: 0.0', ' effect_size: -1.1708036393300898')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.04', ' effect_size: -0.6484227301147325')","('killed: True', 'Sector number: 16', ' p_value: 0.0', ' effect_size: 1.1497609738684216')","('killed: True', 'Sector number: 0', ' p_value: 0.014', ' effect_size: 0.778099066671423')","('killed: True', 'Sector number: 16', ' p_value: 0.002', ' effect_size: 0.9994155477465356')","('killed: True', 'Sector number: 15', ' p_value: 0.019', ' effect_size: -0.7430529116070135')","('killed: True', 'Sector number: 9', ' p_value: 0.015', ' effect_size: 0.7671135757180212')","('killed: True', 'Sector number: 15', ' p_value: 0.04', ' effect_size: -0.6484324654833481')"
42,udacity_make_output_classes_overlap_mutated0_MP_100,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -3.8932670869483768')","('killed: True', 'Sector number: 2', ' p_value: 0.011', ' effect_size: 0.804168042561633')","('killed: True', 'Sector number: 0', ' p_value: 0.031', ' effect_size: -0.6836841305620152')","('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: -0.790439982302555')","('killed: True', 'Sector number: 1', ' p_value: 0.024', ' effect_size: 0.7158910803642988')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: -0.9112860143769645')","('killed: True', 'Sector number: 20', ' p_value: 0.005', ' effect_size: -0.897201611208058')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: 1.1773236589843583')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: -1.6574991989791215')","('killed: True', 'Sector number: 5', ' p_value: 0.0', ' effect_size: -1.2222514151817938')","('killed: True', 'Sector number: 3', ' p_value: 0.004', ' effect_size: -0.9057354262858343')","('killed: True', 'Sector number: 2', ' p_value: 0.036', ' effect_size: -0.6618750190280444')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.2029418229813793')","('killed: True', 'Sector number: 1', ' p_value: 0.02', ' effect_size: 0.7374344742247451')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8626328263305896')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8753910750833895')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.5330050302481437')","('killed: True', 'Sector number: 0', ' p_value: 0.002', ' effect_size: 0.9965411468125562')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: -1.1406837714451974')"
43,udacity_make_output_classes_overlap_mutated0_MP_12.5,"('killed: True', 'Sector number: 3', ' p_value: 0.045', ' effect_size: -0.6331470672563121')","('killed: True', 'Sector number: 1', ' p_value: 0.039', ' effect_size: 0.6526981593475919')","('killed: True', 'Sector number: 0', ' p_value: 0.043', ' effect_size: -0.6390279953526351')","('killed: True', 'Sector number: 23', ' p_value: 0.0', ' effect_size: -1.103622671085776')","('killed: True', 'Sector number: 0', ' p_value: 0.006', ' effect_size: 0.8721025760800016')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.5123192812025286')","('killed: True', 'Sector number: 3', ' p_value: 0.012', ' effect_size: -0.798918433887846')","('killed: True', 'Sector number: 9', ' p_value: 0.008', ' effect_size: 0.8451732935167039')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: -0.9202599576516883')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.132250484095579')","('killed: True', 'Sector number: 3', ' p_value: 0.017', ' effect_size: -0.7546457591181147')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.033', ' effect_size: 0.6726678510901648')",Not killed by this metric,"('killed: True', 'Sector number: 4', ' p_value: 0.004', ' effect_size: 0.9210619230747066')","('killed: True', 'Sector number: 4', ' p_value: 0.003', ' effect_size: -0.9440574403514828')","('killed: True', 'Sector number: 4', ' p_value: 0.037', ' effect_size: 0.6593978254365949')","('killed: True', 'Sector number: 4', ' p_value: 0.004', ' effect_size: -0.910359475533057')"
44,udacity_make_output_classes_overlap_mutated0_MP_25.0,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.5732582916597369')","('killed: True', 'Sector number: 1', ' p_value: 0.04', ' effect_size: 0.6500007224823682')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: -1.1437992533039802')","('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.093155273800089')","('killed: True', 'Sector number: 0', ' p_value: 0.044', ' effect_size: 0.6360950688943823')","('killed: True', 'Sector number: 0', ' p_value: 0.013', ' effect_size: -0.7826313568697356')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9691266812750469')","('killed: True', 'Sector number: 3', ' p_value: 0.018', ' effect_size: 0.7494981275202094')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: -1.64787395510025')","('killed: True', 'Sector number: 7', ' p_value: 0.001', ' effect_size: -1.0994249663424707')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9734138873455888')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9576093271814081')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: -0.9058622999986927')","('killed: True', 'Sector number: 1', ' p_value: 0.02', ' effect_size: 0.7357380941136575')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.9291885381988287')","('killed: True', 'Sector number: 6', ' p_value: 0.046', ' effect_size: 0.629993758631293')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9905842241773979')","('killed: True', 'Sector number: 9', ' p_value: 0.013', ' effect_size: 0.786335983149742')","('killed: True', 'Sector number: 10', ' p_value: 0.005', ' effect_size: -0.8820099875873906')"
45,udacity_make_output_classes_overlap_mutated0_MP_50.0,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -2.753759991788099')","('killed: True', 'Sector number: 20', ' p_value: 0.002', ' effect_size: 0.9748632813760487')","('killed: True', 'Sector number: 1', ' p_value: 0.024', ' effect_size: -0.7155629184697746')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -2.197657817017646')","('killed: True', 'Sector number: 0', ' p_value: 0.038', ' effect_size: 0.6555450820377429')","('killed: True', 'Sector number: 1', ' p_value: 0.009', ' effect_size: -0.830548584226081')","('killed: True', 'Sector number: 1', ' p_value: 0.02', ' effect_size: -0.7361577157109476')","('killed: True', 'Sector number: 13', ' p_value: 0.023', ' effect_size: 0.7176394112846436')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: -1.7521850964020496')","('killed: True', 'Sector number: 5', ' p_value: 0.033', ' effect_size: -0.6740583379558148')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.153352072096142')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.5262392088049535')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: -0.84400191639813')","('killed: True', 'Sector number: 1', ' p_value: 0.028', ' effect_size: 0.6952266448084963')","('killed: True', 'Sector number: 21', ' p_value: 0.016', ' effect_size: 0.7611642261688325')","('killed: True', 'Sector number: 6', ' p_value: 0.001', ' effect_size: 1.0244636830919784')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9833838935438797')","('killed: True', 'Sector number: 5', ' p_value: 0.033', ' effect_size: 0.6760115077951506')","('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: -0.826251721025828')"
46,udacity_make_output_classes_overlap_mutated0_MP_6.25,"('killed: True', 'Sector number: 3', ' p_value: 0.034', ' effect_size: -0.6706962632654397')",Not killed by this metric,"('killed: True', 'Sector number: 23', ' p_value: 0.019', ' effect_size: -0.74310584821626')","('killed: True', 'Sector number: 10', ' p_value: 0.004', ' effect_size: -0.9233936361024377')","('killed: True', 'Sector number: 1', ' p_value: 0.002', ' effect_size: 0.9724765538343083')","('killed: True', 'Sector number: 16', ' p_value: 0.009', ' effect_size: -0.8220235134149155')","('killed: True', 'Sector number: 3', ' p_value: 0.014', ' effect_size: -0.7795382476753441')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.047', ' effect_size: -0.6272394326599927')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.1531118854953584')","('killed: True', 'Sector number: 3', ' p_value: 0.038', ' effect_size: -0.6555242554893287')","('killed: True', 'Sector number: 10', ' p_value: 0.004', ' effect_size: -0.9090466906038825')","('killed: True', 'Sector number: 2', ' p_value: 0.027', ' effect_size: 0.6982618585369302')","('killed: True', 'Sector number: 2', ' p_value: 0.005', ' effect_size: 0.8885412791541268')","('killed: True', 'Sector number: 10', ' p_value: 0.023', ' effect_size: 0.7211691819366777')","('killed: True', 'Sector number: 3', ' p_value: 0.007', ' effect_size: -0.847562507584144')","('killed: True', 'Sector number: 9', ' p_value: 0.046', ' effect_size: 0.6303699471778214')","('killed: True', 'Sector number: 15', ' p_value: 0.031', ' effect_size: -0.6838736060474088')"
47,udacity_remove_activation_function_mutated0_MP_1,"('killed: True', 'Sector number: 12', ' p_value: 0.02', ' effect_size: -0.7368906835226068')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.003', ' effect_size: -0.9348852015898991')","('killed: True', 'Sector number: 10', ' p_value: 0.033', ' effect_size: -0.6726239545496986')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: 1.0618032078828539')","('killed: True', 'Sector number: 0', ' p_value: 0.044', ' effect_size: -0.6368128425509384')","('killed: True', 'Sector number: 16', ' p_value: 0.029', ' effect_size: -0.6896319027064092')","('killed: True', 'Sector number: 3', ' p_value: 0.018', ' effect_size: 0.7512871954589598')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.002', ' effect_size: -1.0010360137500647')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.034', ' effect_size: -0.6705247794106185')","('killed: True', 'Sector number: 25', ' p_value: 0.024', ' effect_size: 0.7128804438671326')","('killed: True', 'Sector number: 2', ' p_value: 0.047', ' effect_size: 0.6273015261012346')","('killed: True', 'Sector number: 15', ' p_value: 0.011', ' effect_size: 0.8044490570305444')","('killed: True', 'Sector number: 15', ' p_value: 0.002', ' effect_size: -0.9797309853050706')","('killed: True', 'Sector number: 9', ' p_value: 0.038', ' effect_size: 0.655086085249521')","('killed: True', 'Sector number: 15', ' p_value: 0.0', ' effect_size: -1.103056020259696')"
48,udacity_remove_activation_function_mutated0_MP_2,"('killed: True', 'Sector number: 20', ' p_value: 0.037', ' effect_size: -0.6599762096398153')","('killed: True', 'Sector number: 1', ' p_value: 0.022', ' effect_size: 0.7245412326903973')","('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: -0.8583673228923426')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.7024943772270913')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.017', ' effect_size: 0.753056235856986')","('killed: True', 'Sector number: 26', ' p_value: 0.043', ' effect_size: -0.6402247713295657')","('killed: True', 'Sector number: 3', ' p_value: 0.037', ' effect_size: -0.6607702107881933')","('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.3780698659070332')","('killed: True', 'Sector number: 3', ' p_value: 0.022', ' effect_size: -0.7258067447689173')","('killed: True', 'Sector number: 26', ' p_value: 0.029', ' effect_size: -0.68935480017107')","('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: 0.7899665719125237')","('killed: True', 'Sector number: 2', ' p_value: 0.04', ' effect_size: 0.6480027840630677')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9903076414723797')","('killed: True', 'Sector number: 1', ' p_value: 0.005', ' effect_size: 0.890596316180409')","('killed: True', 'Sector number: 15', ' p_value: 0.036', ' effect_size: -0.6629937731702342')"
49,udacity_remove_validation_set_mutated0_MP,"('killed: True', 'Sector number: 10', ' p_value: 0.004', ' effect_size: -0.9078877880068689')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.008', ' effect_size: -0.8322800104068464')","('killed: True', 'Sector number: 10', ' p_value: 0.005', ' effect_size: -0.8788501671296658')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.9528742442510096')","('killed: True', 'Sector number: 2', ' p_value: 0.01', ' effect_size: -0.8157073012190567')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.032', ' effect_size: 0.6797867532184367')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.2041014031157595')","('killed: True', 'Sector number: 14', ' p_value: 0.041', ' effect_size: -0.6477061390830818')","('killed: True', 'Sector number: 1', ' p_value: 0.017', ' effect_size: -0.7524867289583628')","('killed: True', 'Sector number: 10', ' p_value: 0.019', ' effect_size: -0.7439046106543709')","('killed: True', 'Sector number: 3', ' p_value: 0.024', ' effect_size: 0.7141377595871392')","('killed: True', 'Sector number: 15', ' p_value: 0.032', ' effect_size: 0.6763144157974216')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.014', ' effect_size: -0.7756443257539247')","('killed: True', 'Sector number: 9', ' p_value: 0.033', ' effect_size: 0.6727552361694116')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9890329949040325')"
50,udacity_unbalance_train_data_mutated0_MP_25.0,"('killed: True', 'Sector number: 0', ' p_value: 0.005', ' effect_size: -0.8888862205070457')","('killed: True', 'Sector number: 6', ' p_value: 0.045', ' effect_size: 0.6350386117509628')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.038', ' effect_size: -0.6569708140562299')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.7519961684572671')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.003', ' effect_size: -0.954993394257141')","('killed: True', 'Sector number: 9', ' p_value: 0.006', ' effect_size: 0.8652504984155802')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.009', ' effect_size: -0.8247593067976285')","('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.171073545964399')","('killed: True', 'Sector number: 0', ' p_value: 0.015', ' effect_size: -0.7693364300635711')","('killed: True', 'Sector number: 23', ' p_value: 0.046', ' effect_size: -0.6312031634219643')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 24', ' p_value: 0.017', ' effect_size: 0.7573072934891262')","('killed: True', 'Sector number: 3', ' p_value: 0.033', ' effect_size: -0.672915752600946')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.005', ' effect_size: -0.8802887092339835')"
51,udacity_unbalance_train_data_mutated0_MP_37.5,"('killed: True', 'Sector number: 10', ' p_value: 0.014', ' effect_size: -0.7785889183632345')",Not killed by this metric,"('killed: True', 'Sector number: 25', ' p_value: 0.008', ' effect_size: -0.8405353045531744')","('killed: True', 'Sector number: 10', ' p_value: 0.002', ' effect_size: -1.002788118107376')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.6779943970772273')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: 0.9561503337569935')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.0050945019709834')","('killed: True', 'Sector number: 14', ' p_value: 0.007', ' effect_size: -0.8521607106535745')","('killed: True', 'Sector number: 11', ' p_value: 0.032', ' effect_size: -0.6782481491605019')","('killed: True', 'Sector number: 10', ' p_value: 0.001', ' effect_size: -1.0595971645313804')","('killed: True', 'Sector number: 26', ' p_value: 0.047', ' effect_size: 0.6281916595469063')","('killed: True', 'Sector number: 2', ' p_value: 0.043', ' effect_size: 0.6412842250092985')","('killed: True', 'Sector number: 25', ' p_value: 0.028', ' effect_size: 0.6936795727406729')",Not killed by this metric,Not killed by this metric,Not killed by this metric
52,udacity_unbalance_train_data_mutated0_MP_43.75,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.2014109961693664')","('killed: True', 'Sector number: 13', ' p_value: 0.033', ' effect_size: 0.6745967295095475')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: -1.072490694038012')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: 1.0119210227191053')","('killed: True', 'Sector number: 2', ' p_value: 0.032', ' effect_size: -0.679864494721019')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.1402926768592676')","('killed: True', 'Sector number: 0', ' p_value: 0.005', ' effect_size: 0.8859982191488197')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.354107010010942')","('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: -0.8215509811490634')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: -1.0152279660844639')","('killed: True', 'Sector number: 0', ' p_value: 0.026', ' effect_size: -0.7025675200366299')","('killed: True', 'Sector number: 3', ' p_value: 0.031', ' effect_size: 0.6829271295066839')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.033', ' effect_size: 0.6753258056305196')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9901217102541009')","('killed: True', 'Sector number: 3', ' p_value: 0.008', ' effect_size: 0.8364680096779297')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.1269701045269886')"
53,udacity_unbalance_train_data_mutated0_MP_46.88,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.444502999958593')","('killed: True', 'Sector number: 13', ' p_value: 0.033', ' effect_size: 0.6724012908899721')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.3423221058854298')","('killed: True', 'Sector number: 0', ' p_value: 0.034', ' effect_size: 0.6712594662197798')","('killed: True', 'Sector number: 2', ' p_value: 0.033', ' effect_size: -0.6730303009783231')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.7666251611506474')","('killed: True', 'Sector number: 0', ' p_value: 0.002', ' effect_size: 0.9915522213656343')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.4586785571379715')","('killed: True', 'Sector number: 0', ' p_value: 0.042', ' effect_size: -0.6433922714335184')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.322079304153218')","('killed: True', 'Sector number: 0', ' p_value: 0.014', ' effect_size: -0.7763732286290895')","('killed: True', 'Sector number: 6', ' p_value: 0.002', ' effect_size: 1.0001827986428946')","('killed: True', 'Sector number: 2', ' p_value: 0.018', ' effect_size: 0.7497850758596365')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.006', ' effect_size: -0.8657612197975567')","('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: 1.0934379617265277')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.4634308440861414')"
54,udacity_unbalance_train_data_mutated0_MP_50.0,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.3667419295499181')","('killed: True', 'Sector number: 6', ' p_value: 0.013', ' effect_size: 0.7849675107459771')","('killed: True', 'Sector number: 21', ' p_value: 0.028', ' effect_size: -0.6967079048116853')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.2371091443371145')","('killed: True', 'Sector number: 0', ' p_value: 0.003', ' effect_size: 0.9289796931505405')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.4433062786806472')","('killed: True', 'Sector number: 0', ' p_value: 0.004', ' effect_size: 0.9050453061265804')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.3271935277091627')","('killed: True', 'Sector number: 0', ' p_value: 0.048', ' effect_size: -0.6265163498982472')","('killed: True', 'Sector number: 0', ' p_value: 0.001', ' effect_size: -1.0133174464935306')","('killed: True', 'Sector number: 10', ' p_value: 0.003', ' effect_size: -0.9522587476824285')","('killed: True', 'Sector number: 6', ' p_value: 0.025', ' effect_size: 0.7094362021817867')","('killed: True', 'Sector number: 21', ' p_value: 0.012', ' effect_size: 0.7928660025755543')","('killed: True', 'Sector number: 21', ' p_value: 0.014', ' effect_size: 0.7786350476287369')","('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: -0.8222335799609345')","('killed: True', 'Sector number: 1', ' p_value: 0.005', ' effect_size: 0.8936691538915452')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.6289405439206615')"
55,udacity_change_activation_function_mutated0_MP_softmax_4,Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.004', ' effect_size: 0.920907374505377')",Not killed by this metric,"('killed: True', 'Sector number: 26', ' p_value: 0.022', ' effect_size: -0.726756090181887')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 2.286603375780129')","('killed: True', 'Sector number: 21', ' p_value: 0.045', ' effect_size: -0.6326665829704213')","('killed: True', 'Sector number: 14', ' p_value: 0.006', ' effect_size: -0.8757641191531641')","('killed: True', 'Sector number: 3', ' p_value: 0.025', ' effect_size: 0.7067227182870447')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.024', ' effect_size: -0.7148466693092485')","('killed: True', 'Sector number: 21', ' p_value: 0.021', ' effect_size: -0.7323091708354075')","('killed: True', 'Sector number: 13', ' p_value: 0.044', ' effect_size: -0.638341526528933')","('killed: True', 'Sector number: 16', ' p_value: 0.024', ' effect_size: -0.713963803240964')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.005', ' effect_size: 0.8902044383630638')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.048', ' effect_size: 0.6248456229477931')",Not killed by this metric
56,udacity_change_activation_function_mutated0_MP_tanh_4,Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.035', ' effect_size: 0.6673074290545554')","('killed: True', 'Sector number: 15', ' p_value: 0.024', ' effect_size: -0.7115354546902767')","('killed: True', 'Sector number: 10', ' p_value: 0.014', ' effect_size: -0.7735272654431363')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.2826771220875939')","('killed: True', 'Sector number: 16', ' p_value: 0.009', ' effect_size: -0.8236271153069252')","('killed: True', 'Sector number: 12', ' p_value: 0.011', ' effect_size: -0.7999476507347548')","('killed: True', 'Sector number: 16', ' p_value: 0.011', ' effect_size: 0.805224215367478')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: -0.9872302014533015')","('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.103048520855582')","('killed: True', 'Sector number: 10', ' p_value: 0.044', ' effect_size: -0.6367013065946043')","('killed: True', 'Sector number: 10', ' p_value: 0.02', ' effect_size: -0.7342951927709915')","('killed: True', 'Sector number: 25', ' p_value: 0.047', ' effect_size: 0.6278968108905677')",Not killed by this metric,"('killed: True', 'Sector number: 24', ' p_value: 0.034', ' effect_size: 0.669244177269774')","('killed: True', 'Sector number: 3', ' p_value: 0.013', ' effect_size: -0.7865800952414115')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.048', ' effect_size: -0.6255118828050275')"
57,udacity_change_dropout_rate_mutated0_MP_0.25_0.25_6,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8494208768974884')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: -1.0788513698223292')","('killed: True', 'Sector number: 10', ' p_value: 0.006', ' effect_size: -0.8665482643148461')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.7135693054024823')","('killed: True', 'Sector number: 15', ' p_value: 0.004', ' effect_size: -0.914645617269821')","('killed: True', 'Sector number: 14', ' p_value: 0.013', ' effect_size: -0.7859647055019865')","('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: 0.9598931829008586')",Not killed by this metric,"('killed: True', 'Sector number: 21', ' p_value: 0.001', ' effect_size: -1.0338502022620122')","('killed: True', 'Sector number: 15', ' p_value: 0.013', ' effect_size: -0.7821264165981837')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.012', ' effect_size: -0.7944072244946377')","('killed: True', 'Sector number: 2', ' p_value: 0.008', ' effect_size: 0.8325059275421229')","('killed: True', 'Sector number: 0', ' p_value: 0.011', ' effect_size: 0.8042176655276958')","('killed: True', 'Sector number: 2', ' p_value: 0.047', ' effect_size: 0.6289419988262218')","('killed: True', 'Sector number: 3', ' p_value: 0.023', ' effect_size: -0.7165262188875734')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0556815607185')","('killed: True', 'Sector number: 2', ' p_value: 0.04', ' effect_size: -0.6506453512031454')"
58,udacity_change_dropout_rate_mutated0_MP_1.0_1.0_6,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8469636641843987')","('killed: True', 'Sector number: 2', ' p_value: 0.023', ' effect_size: -0.7202355821500597')","('killed: True', 'Sector number: 10', ' p_value: 0.004', ' effect_size: -0.907089215423228')","('killed: True', 'Sector number: 0', ' p_value: 0.007', ' effect_size: 0.849397818854412')","('killed: True', 'Sector number: 15', ' p_value: 0.037', ' effect_size: -0.6609191052437885')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.049', ' effect_size: 0.6214089672131442')",Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.023', ' effect_size: -0.7191522006086148')","('killed: True', 'Sector number: 12', ' p_value: 0.004', ' effect_size: -0.908899997404571')","('killed: True', 'Sector number: 13', ' p_value: 0.024', ' effect_size: -0.7145110450514419')","('killed: True', 'Sector number: 10', ' p_value: 0.0', ' effect_size: -1.111731827598784')","('killed: True', 'Sector number: 2', ' p_value: 0.037', ' effect_size: 0.6582048960520587')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0201408787079242')","('killed: True', 'Sector number: 15', ' p_value: 0.009', ' effect_size: 0.8286382530641384')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.2681975875542004')","('killed: True', 'Sector number: 2', ' p_value: 0.02', ' effect_size: 0.734560465014024')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.0107836119402875')"
59,udacity_change_label_mutated0_MP_18.75,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.8661962551710192')","('killed: True', 'Sector number: 2', ' p_value: 0.004', ' effect_size: -0.9108046936075838')","('killed: True', 'Sector number: 15', ' p_value: 0.049', ' effect_size: -0.6232632442596346')","('killed: True', 'Sector number: 1', ' p_value: 0.003', ' effect_size: 0.9506405110771959')","('killed: True', 'Sector number: 16', ' p_value: 0.013', ' effect_size: -0.7892189324898414')","('killed: True', 'Sector number: 16', ' p_value: 0.037', ' effect_size: -0.6595516038080392')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: 1.153443812870433')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 12', ' p_value: 0.014', ' effect_size: -0.7808319687681015')","('killed: True', 'Sector number: 3', ' p_value: 0.019', ' effect_size: -0.7446940177613895')","('killed: True', 'Sector number: 10', ' p_value: 0.024', ' effect_size: -0.7149579198854727')","('killed: True', 'Sector number: 2', ' p_value: 0.006', ' effect_size: 0.873775696091641')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0924613977864548')","('killed: True', 'Sector number: 20', ' p_value: 0.018', ' effect_size: 0.7500326016530604')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3458393691710733')","('killed: True', 'Sector number: 2', ' p_value: 0.023', ' effect_size: 0.7179935901513153')","('killed: True', 'Sector number: 2', ' p_value: 0.032', ' effect_size: -0.6766458729234249')"
60,udacity_change_weights_initialisation_mutated0_MP_truncated_normal_4,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.9545890705844191')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: -1.0466843104336423')","('killed: True', 'Sector number: 10', ' p_value: 0.005', ' effect_size: -0.8883709717488116')","('killed: True', 'Sector number: 0', ' p_value: 0.043', ' effect_size: 0.6414367434183477')","('killed: True', 'Sector number: 9', ' p_value: 0.01', ' effect_size: -0.8128017135695079')","('killed: True', 'Sector number: 14', ' p_value: 0.029', ' effect_size: -0.6900221308844705')","('killed: True', 'Sector number: 8', ' p_value: 0.046', ' effect_size: 0.6314717975806421')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.240604108127415')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.009', ' effect_size: -0.8266420704427757')","('killed: True', 'Sector number: 2', ' p_value: 0.023', ' effect_size: 0.7190621052584808')","('killed: True', 'Sector number: 0', ' p_value: 0.017', ' effect_size: 0.7520197655341674')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.5150848274563624')","('killed: True', 'Sector number: 2', ' p_value: 0.019', ' effect_size: 0.7413936160249462')","('killed: True', 'Sector number: 15', ' p_value: 0.024', ' effect_size: -0.7152923004389862')"
61,udacity_delete_training_data_mutated0_MP_12.38,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.048', ' effect_size: 0.6244805172739232')","('killed: True', 'Sector number: 2', ' p_value: 0.02', ' effect_size: -0.7357340142303949')","('killed: True', 'Sector number: 21', ' p_value: 0.045', ' effect_size: -0.6324743115526256')","('killed: True', 'Sector number: 0', ' p_value: 0.005', ' effect_size: 0.8836948152231786')","('killed: True', 'Sector number: 21', ' p_value: 0.014', ' effect_size: -0.777494711136073')","('killed: True', 'Sector number: 20', ' p_value: 0.002', ' effect_size: -0.9809189773813979')","('killed: True', 'Sector number: 3', ' p_value: 0.009', ' effect_size: 0.827842939785999')",Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 21', ' p_value: 0.015', ' effect_size: -0.76601150482723')","('killed: True', 'Sector number: 21', ' p_value: 0.017', ' effect_size: 0.7567600579005376')","('killed: True', 'Sector number: 2', ' p_value: 0.009', ' effect_size: 0.8228814171463724')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3292100269208134')","('killed: True', 'Sector number: 15', ' p_value: 0.026', ' effect_size: 0.7041464030195804')","('killed: True', 'Sector number: 3', ' p_value: 0.012', ' effect_size: -0.7955296158261513')"
62,udacity_delete_training_data_mutated0_MP_15.48,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8600095249852652')","('killed: True', 'Sector number: 15', ' p_value: 0.007', ' effect_size: -0.8592897943937358')","('killed: True', 'Sector number: 23', ' p_value: 0.038', ' effect_size: -0.6557172230389344')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.1730730783924517')","('killed: True', 'Sector number: 16', ' p_value: 0.03', ' effect_size: -0.68489791664002')","('killed: True', 'Sector number: 20', ' p_value: 0.013', ' effect_size: -0.7884257990991074')","('killed: True', 'Sector number: 20', ' p_value: 0.011', ' effect_size: 0.8075687603814882')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 16', ' p_value: 0.048', ' effect_size: -0.624317643214477')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.038', ' effect_size: -0.6547287853123774')","('killed: True', 'Sector number: 16', ' p_value: 0.033', ' effect_size: 0.6748010324686861')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.1233339779652063')","('killed: True', 'Sector number: 15', ' p_value: 0.027', ' effect_size: 0.7012284181560142')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.233916637742115')","('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8527538842414819')","('killed: True', 'Sector number: 4', ' p_value: 0.031', ' effect_size: -0.6825614948167593')"
63,udacity_remove_activation_function_mutated0_MP_3,Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.027', ' effect_size: 0.697689776548149')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: -0.9411272210447154')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: 1.1622722605973168')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.018', ' effect_size: 0.7451696339420335')","('killed: True', 'Sector number: 26', ' p_value: 0.035', ' effect_size: -0.6658367811203066')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.018', ' effect_size: -0.7472535028562941')","('killed: True', 'Sector number: 3', ' p_value: 0.008', ' effect_size: -0.8394187638854362')",Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: 0.7915318723807296')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0800339674081345')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.015', ' effect_size: -0.7680587278719841')","('killed: True', 'Sector number: 2', ' p_value: 0.032', ' effect_size: 0.6781180529126316')",Not killed by this metric
64,udacity_change_activation_function_mutated0_MP_softplus_4,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.009', ' effect_size: -0.8208589301864027')","('killed: True', 'Sector number: 11', ' p_value: 0.023', ' effect_size: -0.7207709023451316')","('killed: True', 'Sector number: 1', ' p_value: 0.021', ' effect_size: 0.7286858031837697')","('killed: True', 'Sector number: 15', ' p_value: 0.022', ' effect_size: -0.7224856394315999')",Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.002', ' effect_size: 0.9566326872242316')","('killed: True', 'Sector number: 19', ' p_value: 0.03', ' effect_size: -0.686157631209177')","('killed: True', 'Sector number: 16', ' p_value: 0.009', ' effect_size: -0.8264734924728692')","('killed: True', 'Sector number: 3', ' p_value: 0.024', ' effect_size: -0.7123690556089295')",Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.014', ' effect_size: -0.7734441724762865')","('killed: True', 'Sector number: 2', ' p_value: 0.01', ' effect_size: 0.8174421939278044')","('killed: True', 'Sector number: 2', ' p_value: 0.001', ' effect_size: 1.0087456167594298')","('killed: True', 'Sector number: 15', ' p_value: 0.036', ' effect_size: 0.6643373176657517')","('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.0970276139743282')","('killed: True', 'Sector number: 2', ' p_value: 0.015', ' effect_size: 0.7722887115318247')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.027805618062036')"
65,udacity_change_learning_rate_mutated0_MP_False_4e-05,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -1.6884289713327394')","('killed: True', 'Sector number: 2', ' p_value: 0.03', ' effect_size: -0.6851195139357883')","('killed: True', 'Sector number: 0', ' p_value: 0.011', ' effect_size: 0.8043344273380079')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.0932126536329965')","('killed: True', 'Sector number: 1', ' p_value: 0.006', ' effect_size: -0.8616331963504761')","('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: 1.0484223298033455')","('killed: True', 'Sector number: 0', ' p_value: 0.0', ' effect_size: -2.0537918632467345')",Not killed by this metric,"('killed: True', 'Sector number: 12', ' p_value: 0.004', ' effect_size: -0.900914882376726')","('killed: True', 'Sector number: 3', ' p_value: 0.046', ' effect_size: -0.631105394822711')","('killed: True', 'Sector number: 0', ' p_value: 0.017', ' effect_size: -0.7553294634335515')","('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: 1.044844893750541')","('killed: True', 'Sector number: 2', ' p_value: 0.003', ' effect_size: 0.9326566770511283')","('killed: True', 'Sector number: 2', ' p_value: 0.007', ' effect_size: 0.8509069949722537')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.6185577925411048')","('killed: True', 'Sector number: 6', ' p_value: 0.009', ' effect_size: 0.8320096167410117')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: -1.2312561453023227')"
66,udacity_change_learning_rate_mutated0_MP_False_7e-05,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.012', ' effect_size: -0.7972913117388251')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.042', ' effect_size: 0.6426623703923832')",Not killed by this metric,"('killed: True', 'Sector number: 20', ' p_value: 0.0', ' effect_size: -1.1047143163896889')",Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 12', ' p_value: 0.007', ' effect_size: -0.8548508450164197')",Not killed by this metric,"('killed: True', 'Sector number: 0', ' p_value: 0.046', ' effect_size: -0.6317514659260955')","('killed: True', 'Sector number: 16', ' p_value: 0.043', ' effect_size: 0.6411114159217778')","('killed: True', 'Sector number: 0', ' p_value: 0.027', ' effect_size: 0.7013869265084135')","('killed: True', 'Sector number: 20', ' p_value: 0.006', ' effect_size: 0.8751375323088605')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.3758652027150853')","('killed: True', 'Sector number: 9', ' p_value: 0.042', ' effect_size: 0.644433356279257')","('killed: True', 'Sector number: 4', ' p_value: 0.049', ' effect_size: -0.6234937521923353')"
67,udacity_delete_training_data_mutated0_MP_24.75,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 2', ' p_value: 0.015', ' effect_size: -0.7693530682333513')","('killed: True', 'Sector number: 11', ' p_value: 0.008', ' effect_size: -0.8344018310260446')","('killed: True', 'Sector number: 0', ' p_value: 0.037', ' effect_size: 0.6590432777368802')","('killed: True', 'Sector number: 0', ' p_value: 0.048', ' effect_size: -0.6239917092859898')","('killed: True', 'Sector number: 20', ' p_value: 0.001', ' effect_size: -1.0070782248887211')","('killed: True', 'Sector number: 23', ' p_value: 0.045', ' effect_size: 0.6334489485546873')","('killed: True', 'Sector number: 15', ' p_value: 0.001', ' effect_size: -1.0218642344276136')","('killed: True', 'Sector number: 21', ' p_value: 0.015', ' effect_size: -0.7679392383929224')","('killed: True', 'Sector number: 12', ' p_value: 0.02', ' effect_size: -0.7361925045817521')","('killed: True', 'Sector number: 13', ' p_value: 0.022', ' effect_size: -0.7253336969263985')","('killed: True', 'Sector number: 24', ' p_value: 0.013', ' effect_size: -0.782075598865863')","('killed: True', 'Sector number: 16', ' p_value: 0.002', ' effect_size: 0.9752773699775084')","('killed: True', 'Sector number: 0', ' p_value: 0.038', ' effect_size: 0.6577552193501963')","('killed: True', 'Sector number: 15', ' p_value: 0.028', ' effect_size: 0.6943933725764998')","('killed: True', 'Sector number: 3', ' p_value: 0.001', ' effect_size: -1.0278817651212868')",Not killed by this metric,"('killed: True', 'Sector number: 15', ' p_value: 0.009', ' effect_size: -0.8249392898851294')"
68,udacity_delete_training_data_mutated0_MP_34.02,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 13', ' p_value: 0.041', ' effect_size: -0.6454308630705924')","('killed: True', 'Sector number: 10', ' p_value: 0.011', ' effect_size: -0.8071615660974847')","('killed: True', 'Sector number: 1', ' p_value: 0.0', ' effect_size: 1.1346472064843396')","('killed: True', 'Sector number: 13', ' p_value: 0.03', ' effect_size: -0.688061126355232')","('killed: True', 'Sector number: 14', ' p_value: 0.004', ' effect_size: -0.9215412510812468')",Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 3', ' p_value: 0.013', ' effect_size: -0.7880420333294451')","('killed: True', 'Sector number: 12', ' p_value: 0.048', ' effect_size: -0.6253083365494513')","('killed: True', 'Sector number: 13', ' p_value: 0.017', ' effect_size: -0.753638254591424')","('killed: True', 'Sector number: 10', ' p_value: 0.001', ' effect_size: -1.007741930281031')","('killed: True', 'Sector number: 16', ' p_value: 0.015', ' effect_size: 0.7708373485973838')","('killed: True', 'Sector number: 13', ' p_value: 0.024', ' effect_size: 0.7123062721842259')","('killed: True', 'Sector number: 20', ' p_value: 0.003', ' effect_size: 0.9311859376112308')","('killed: True', 'Sector number: 3', ' p_value: 0.0', ' effect_size: -1.111539321202187')","('killed: True', 'Sector number: 13', ' p_value: 0.031', ' effect_size: 0.6832634479709635')","('killed: True', 'Sector number: 13', ' p_value: 0.048', ' effect_size: -0.6259490499617831')"
69,udacity_make_output_classes_overlap_mutated0_MP_9.38,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 1', ' p_value: 0.036', ' effect_size: -0.6637893457133974')","('killed: True', 'Sector number: 23', ' p_value: 0.045', ' effect_size: -0.6331884390998465')","('killed: True', 'Sector number: 2', ' p_value: 0.0', ' effect_size: 1.1716994889145445')","('killed: True', 'Sector number: 1', ' p_value: 0.041', ' effect_size: -0.6476655778471181')",Not killed by this metric,"('killed: True', 'Sector number: 9', ' p_value: 0.023', ' effect_size: 0.7170606986428524')","('killed: True', 'Sector number: 1', ' p_value: 0.001', ' effect_size: -1.0228012680440894')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.0', ' effect_size: -1.1497774536053555')",Not killed by this metric,"('killed: True', 'Sector number: 14', ' p_value: 0.004', ' effect_size: -0.918864994401555')","('killed: True', 'Sector number: 2', ' p_value: 0.033', ' effect_size: 0.6744555345571592')","('killed: True', 'Sector number: 13', ' p_value: 0.047', ' effect_size: 0.6274424634908086')","('killed: True', 'Sector number: 4', ' p_value: 0.006', ' effect_size: 0.8617651478394902')","('killed: True', 'Sector number: 3', ' p_value: 0.033', ' effect_size: -0.6748811329933235')",Not killed by this metric,"('killed: True', 'Sector number: 13', ' p_value: 0.022', ' effect_size: -0.7245100707638579')"
70,udacity_remove_bias_mutated0_MP_3,Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 10', ' p_value: 0.046', ' effect_size: -0.6301363085982892')","('killed: True', 'Sector number: 0', ' p_value: 0.008', ' effect_size: 0.8434816081024797')","('killed: True', 'Sector number: 16', ' p_value: 0.013', ' effect_size: -0.7875034683796331')",Not killed by this metric,"('killed: True', 'Sector number: 5', ' p_value: 0.004', ' effect_size: 0.9161534975718104')","('killed: True', 'Sector number: 15', ' p_value: 0.046', ' effect_size: -0.6311214208924694')","('killed: True', 'Sector number: 0', ' p_value: 0.034', ' effect_size: -0.6694913218351973')","('killed: True', 'Sector number: 16', ' p_value: 0.047', ' effect_size: -0.6279643519491266')","('killed: True', 'Sector number: 11', ' p_value: 0.009', ' effect_size: -0.8210593657509594')",Not killed by this metric,Not killed by this metric,Not killed by this metric,Not killed by this metric,"('killed: True', 'Sector number: 4', ' p_value: 0.048', ' effect_size: -0.6264367196920787')",Not killed by this metric,Not killed by this metric
